{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Anysee Tutorial - Face Detection / Recognition basic API usages\n",
    "\n",
    "In this example we will first show how to use the Face Detection API to detect faces of images on the internet. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "import logging\n",
    "import requests\n",
    "from requests.structures import CaseInsensitiveDict\n",
    "\n",
    "region = 'ap-northeast-1' # this is the region we picked when we created the instance\n",
    "endpoint = 'api/v1/entities/faces/detect'\n",
    "\n",
    "url = f'https://anysee.{region}.cloud.japancv.co.jp/{endpoint}'\n",
    "apikey = 'e6a26ecd-7b43-4fc8-bfad-04e82e0a3848'\n",
    "headers = CaseInsensitiveDict()\n",
    "headers['Content-Type'] = 'application/json'\n",
    "headers['api-key'] = apikey"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we have the REST request body for doing the detection. See the [docs](https://docs.cloud.japancv.co.jp/docs/anysee-introduction) for more information.\n",
    "\n",
    "For the parameters, img is the image in base64 format.\n",
    "\n",
    "`pos` stands for the position, `ang` stands for angle, `lnd` stands for landmark locations, `qua` stands for the quality of the face, and `att` stands for the attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sendRequest(img:str, pos=False, ang=False, lnd=False, qua=False, att=False):\n",
    "    data = {}\n",
    "    image = {}\n",
    "    rd = {}\n",
    "    rd[\"position\"] = pos\n",
    "    rd[\"angle\"] = ang\n",
    "    rd[\"landmarks\"] = lnd\n",
    "    rd[\"quality\"] = qua\n",
    "    rd[\"attributes\"] = att\n",
    "    image['data'] = img\n",
    "    image['autoRotate'] = True\n",
    "    image['returnDetails'] = rd\n",
    "    data['model'] = 'JCV_FACE_K25000'\n",
    "    data['image'] = image\n",
    "    success = True\n",
    "    try:\n",
    "        res = requests.post(url, json=data, headers=headers, timeout=10)\n",
    "    except Exception as e:\n",
    "        logging.warning(f'Anysee timeout! {e}')\n",
    "        res = 'Anysee endpoint timeout'\n",
    "        success = False\n",
    "    if res == 'Anysee endpoint timeout' or res.status_code != 200:\n",
    "        success = False\n",
    "    return res, success"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The API requires a base64 format of the image data, so let's make a function to convert the data to base64 format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def b64(image_path):\n",
    "    with open(image_path, \"rb\") as image_file:\n",
    "        encode = base64.b64encode(image_file.read()).decode('utf-8')\n",
    "    return encode"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to download a random image from the internet for the demo. Feel free to change the image used here. We'll read it in again later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_data = requests.get('https://img.kyodonews.net/english/public/images/posts/ed58f81ded6f4ac7f66e61fed97fbe39/photo_l.jpg').content\n",
    "with open('sample.jpg', 'wb') as handler:\n",
    "    handler.write(img_data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the example image that we need, let's start doing some face detection!\n",
    "Read the imageand send the request. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "req_img = b64('sample.jpg')\n",
    "res, suc = sendRequest(req_img, pos=True, ang=True, lnd=True, qua=True, att=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model': 'JCV_FACE_K25000',\n",
       " 'count': 1,\n",
       " 'entities': [{'rotated': 0,\n",
       "   'details': {'position': {'top': 364,\n",
       "     'left': 290,\n",
       "     'width': 377,\n",
       "     'height': 394},\n",
       "    'angle': {'yaw': -0.4502186,\n",
       "     'pitch': 2.913058,\n",
       "     'roll': -0.5153649,\n",
       "     'centerX': 478,\n",
       "     'centerY': 561},\n",
       "    'landmarks': [{'x': 297, 'y': 456},\n",
       "     {'x': 297, 'y': 482},\n",
       "     {'x': 298, 'y': 508},\n",
       "     {'x': 300, 'y': 535},\n",
       "     {'x': 303, 'y': 560},\n",
       "     {'x': 307, 'y': 586},\n",
       "     {'x': 311, 'y': 612},\n",
       "     {'x': 318, 'y': 636},\n",
       "     {'x': 328, 'y': 660},\n",
       "     {'x': 342, 'y': 682},\n",
       "     {'x': 358, 'y': 703},\n",
       "     {'x': 377, 'y': 719},\n",
       "     {'x': 396, 'y': 736},\n",
       "     {'x': 418, 'y': 750},\n",
       "     {'x': 439, 'y': 762},\n",
       "     {'x': 463, 'y': 767},\n",
       "     {'x': 487, 'y': 767},\n",
       "     {'x': 513, 'y': 766},\n",
       "     {'x': 537, 'y': 760},\n",
       "     {'x': 558, 'y': 748},\n",
       "     {'x': 579, 'y': 734},\n",
       "     {'x': 597, 'y': 717},\n",
       "     {'x': 615, 'y': 697},\n",
       "     {'x': 630, 'y': 677},\n",
       "     {'x': 642, 'y': 655},\n",
       "     {'x': 652, 'y': 632},\n",
       "     {'x': 655, 'y': 606},\n",
       "     {'x': 662, 'y': 581},\n",
       "     {'x': 663, 'y': 554},\n",
       "     {'x': 665, 'y': 529},\n",
       "     {'x': 668, 'y': 504},\n",
       "     {'x': 666, 'y': 478},\n",
       "     {'x': 667, 'y': 452},\n",
       "     {'x': 338, 'y': 418},\n",
       "     {'x': 361, 'y': 392},\n",
       "     {'x': 388, 'y': 385},\n",
       "     {'x': 417, 'y': 386},\n",
       "     {'x': 446, 'y': 395},\n",
       "     {'x': 516, 'y': 396},\n",
       "     {'x': 543, 'y': 388},\n",
       "     {'x': 571, 'y': 386},\n",
       "     {'x': 601, 'y': 392},\n",
       "     {'x': 623, 'y': 416},\n",
       "     {'x': 482, 'y': 454},\n",
       "     {'x': 482, 'y': 487},\n",
       "     {'x': 482, 'y': 520},\n",
       "     {'x': 485, 'y': 553},\n",
       "     {'x': 442, 'y': 580},\n",
       "     {'x': 463, 'y': 584},\n",
       "     {'x': 485, 'y': 589},\n",
       "     {'x': 504, 'y': 583},\n",
       "     {'x': 526, 'y': 580},\n",
       "     {'x': 369, 'y': 460},\n",
       "     {'x': 384, 'y': 452},\n",
       "     {'x': 421, 'y': 452},\n",
       "     {'x': 435, 'y': 464},\n",
       "     {'x': 419, 'y': 467},\n",
       "     {'x': 384, 'y': 466},\n",
       "     {'x': 527, 'y': 463},\n",
       "     {'x': 540, 'y': 452},\n",
       "     {'x': 578, 'y': 450},\n",
       "     {'x': 594, 'y': 460},\n",
       "     {'x': 579, 'y': 466},\n",
       "     {'x': 545, 'y': 466},\n",
       "     {'x': 362, 'y': 412},\n",
       "     {'x': 389, 'y': 408},\n",
       "     {'x': 417, 'y': 410},\n",
       "     {'x': 444, 'y': 413},\n",
       "     {'x': 516, 'y': 414},\n",
       "     {'x': 543, 'y': 409},\n",
       "     {'x': 571, 'y': 409},\n",
       "     {'x': 598, 'y': 413},\n",
       "     {'x': 402, 'y': 448},\n",
       "     {'x': 402, 'y': 468},\n",
       "     {'x': 402, 'y': 460},\n",
       "     {'x': 559, 'y': 448},\n",
       "     {'x': 562, 'y': 467},\n",
       "     {'x': 560, 'y': 459},\n",
       "     {'x': 458, 'y': 458},\n",
       "     {'x': 504, 'y': 458},\n",
       "     {'x': 444, 'y': 536},\n",
       "     {'x': 523, 'y': 536},\n",
       "     {'x': 430, 'y': 563},\n",
       "     {'x': 537, 'y': 563},\n",
       "     {'x': 417, 'y': 641},\n",
       "     {'x': 442, 'y': 630},\n",
       "     {'x': 470, 'y': 626},\n",
       "     {'x': 484, 'y': 629},\n",
       "     {'x': 500, 'y': 626},\n",
       "     {'x': 527, 'y': 629},\n",
       "     {'x': 552, 'y': 639},\n",
       "     {'x': 532, 'y': 655},\n",
       "     {'x': 509, 'y': 667},\n",
       "     {'x': 486, 'y': 669},\n",
       "     {'x': 460, 'y': 667},\n",
       "     {'x': 437, 'y': 656},\n",
       "     {'x': 426, 'y': 643},\n",
       "     {'x': 456, 'y': 642},\n",
       "     {'x': 485, 'y': 645},\n",
       "     {'x': 513, 'y': 642},\n",
       "     {'x': 542, 'y': 640},\n",
       "     {'x': 514, 'y': 644},\n",
       "     {'x': 485, 'y': 645},\n",
       "     {'x': 456, 'y': 643},\n",
       "     {'x': 402, 'y': 460},\n",
       "     {'x': 560, 'y': 459}],\n",
       "    'quality': {'brightness': 0.09019608,\n",
       "     'sharpness': 0.99812496,\n",
       "     'mouthClosed': 0.9816347,\n",
       "     'centered': 0.8864476,\n",
       "     'size': 0.11016946,\n",
       "     'integrity': 1,\n",
       "     'completeness': {'total': 0.989252,\n",
       "      'leftEyeBrow': 0.9990943,\n",
       "      'rightEyeBrow': 0.99763036,\n",
       "      'leftEye': 0.9999129,\n",
       "      'rightEye': 0.9998955,\n",
       "      'nose': 0.99969685,\n",
       "      'mouth': 0.999139,\n",
       "      'faceContour': 0.96836567}},\n",
       "    'attributes': {'age': {'value': 55, 'upperLimit': 60, 'lowerLimit': 50},\n",
       "     'gender': {'value': 'male', 'certainty': 0.9999485611915588},\n",
       "     'bangs': {'value': 'without_bangs', 'certainty': 0.9999999403953552},\n",
       "     'facialHair': {'value': 'without_facial_hair',\n",
       "      'certainty': 0.9992849826812744},\n",
       "     'helmet': {'value': 'without_helmet', 'certainty': 0.9997546076774597},\n",
       "     'hat': {'value': 'without_hat', 'certainty': 0.9999709129333496},\n",
       "     'headphones': {'value': 'without_headphones',\n",
       "      'certainty': 0.9999291300773621},\n",
       "     'glasses': {'value': 'with_transparent_glasses',\n",
       "      'certainty': 0.9908433556556702},\n",
       "     'mask': {'value': 'without_mask', 'certainty': 0.9997501373291016},\n",
       "     'emotions': [{'value': 'angry', 'certainty': 0.00011262675980105996},\n",
       "      {'value': 'happy', 'certainty': 0.0004005885566584766},\n",
       "      {'value': 'sad', 'certainty': 0.0003769049944821745},\n",
       "      {'value': 'calm', 'certainty': 0.9990901947021484},\n",
       "      {'value': 'surprised', 'certainty': 1.4780510355194565e-05},\n",
       "      {'value': 'scared', 'certainty': 2.091303258566768e-06},\n",
       "      {'value': 'disgusted', 'certainty': 2.056159331687013e-07},\n",
       "      {'value': 'sleepy', 'certainty': 2.5625081434554886e-06}]}}}]}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(res)\n",
    "res.json()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
